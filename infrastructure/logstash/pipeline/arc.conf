# Arc Logstash Pipeline Configuration

input {
  # Receive logs from Docker containers
  tcp {
    port => 5044
    codec => json_lines
  }
  
  # HTTP input for direct API logging
  http {
    port => 5045
    codec => json
  }
}

filter {
  # Parse timestamp
  if [@timestamp] {
    date {
      match => ["@timestamp", "ISO8601"]
      target => "@timestamp"
    }
  }
  
  # Add index name based on log type
  if [app_name] == "Arc" {
    mutate {
      add_field => { "[@metadata][index_prefix]" => "arc" }
    }
    
    # Categorize by log type
    if [scan_id] {
      mutate {
        add_field => { "[@metadata][index_type]" => "scans" }
      }
    } else if [security_event_type] {
      mutate {
        add_field => { "[@metadata][index_type]" => "security" }
      }
    } else if [tool_name] {
      mutate {
        add_field => { "[@metadata][index_type]" => "tools" }
      }
    } else {
      mutate {
        add_field => { "[@metadata][index_type]" => "app" }
      }
    }
  } else {
    mutate {
      add_field => { "[@metadata][index_prefix]" => "arc" }
      add_field => { "[@metadata][index_type]" => "other" }
    }
  }
  
  # Parse severity for vulnerabilities
  if [severity] {
    mutate {
      lowercase => ["severity"]
    }
  }
  
  # Mask sensitive data
  if [password] {
    mutate {
      replace => { "password" => "[REDACTED]" }
    }
  }
  
  if [api_key] {
    mutate {
      replace => { "api_key" => "[REDACTED]" }
    }
  }
  
  # Add geo data for IPs
  if [source_ip] and [source_ip] !~ /^(10\.|172\.(1[6-9]|2[0-9]|3[01])\.|192\.168\.|127\.)/ {
    geoip {
      source => "source_ip"
      target => "geoip"
    }
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "%{[@metadata][index_prefix]}-%{[@metadata][index_type]}-%{+YYYY.MM.dd}"
  }
  
  # Debug output (remove in production)
  # stdout {
  #   codec => rubydebug
  # }
}
